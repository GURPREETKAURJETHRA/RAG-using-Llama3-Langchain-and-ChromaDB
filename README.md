# ğŸŒŸRAG using Llama3, Langchain and ChromaDBğŸ’
RAG using Llama3, Langchain and ChromaDB

## Objective ğŸ¯

This project utilizes Llama3 Langchain and ChromaDB to establish a Retrieval Augmented Generation (RAG) system. This system empowers you to ask questions about your documents, even if the information wasn't included in the training data for the Large Language Model (LLM). Retrieval Augmented Generation works by first performing a retrieval step when presented with a question. This step fetches relevant documents from a special vector database, where the documents have been indexed.

### Definitions ğŸ“

* **LLM:** Large Language Model
* **Llama3:** LLM developed by Meta
* **Langchain:** Framework designed to streamline the creation of applications utilizing LLMs
* **Vector database:** Database that organizes data using high-dimensional vectors
* **ChromaDB:** Vector database
* **RAG:** Retrieval Augmented Generation (see below for more details)

### Model Details ğŸŒŸ

* **Model:** Llama 3
* **Variation:** 8b-chat-hf (8b: 8 Billion parameters; hf: HuggingFace)
* **Version:** V1
* **Framework:** Transformers

The pre-trained Llama3 model is fine-tuned with over 15 Trillion tokens and boasts 8 to 70 Billion parameters, making it one of the most powerful open-source models available. It offers significant advancements over the previous Llama2 model.


## Conclusions ğŸ’¯ğŸ”¥

This project successfully implemented a Retrieval Augmented Generation (RAG) solution by leveraging Langchain, ChromaDB, and Llama3 as the LLM. To evaluate the system's performance, we utilized the EU AI Act from 2023. The results demonstrated that the RAG model delivers accurate answers to questions posed about the Act.

**Future Work** âš¡âœ¨

To further enhance the solution, we will focus on refining the RAG implementation. This will involve optimizing the document embeddings and exploring the use of more intricate RAG architectures.

---
**ğŸ’ğŸŒŸMETA LLAMA3 GENAI Real World UseCases End To End Implementation GuidesğŸ“ğŸ“šâš¡**

1. Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/fsdp-qlora-distributed-llama3.ipynb)

2. Deploy Llama 3 on Amazon SageMaker : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/deploy-llama3.ipynb)

3. RAG using Llama3, Langchain and ChromaDB : [ğŸ‘‰Implementation Guide 1â–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/rag-using-llama3-langchain-and-chromadb.ipynb)

4. Prompting Llama 3 like a Pro : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/prompting-llama-3-like-a-pro.ipynb)

5. Test Llama3 with some Math Questions : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/test-llama3-with-some-math-questions.ipynb)

6. Llama3 please write code for me : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/llama3-please-write-code-for-me.ipynb)

7. Run LLAMA-3 70B LLM with NVIDIA endpoints on Amazing Streamlit UI : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/LLAMA3-70B-LLM-with-NVIDIA)

8. Llama 3 ORPO Fine Tuning : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning)

9. Meta's LLaMA3-Quantization : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/LLaMA3-Quantization)

10. Finetune Llama3 using QLoRA : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/finetune-llama3-using-qlora.ipynb)

11. Llama3 Qlora Inference : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/llama3-qlora-inference.ipynb)

12. Beam_Llama3-8B-finetune_task : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/Beam_Llama3-8B-finetune_task.py)

13. Llama-3 Finetuning on custom dataset with Unsloth : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/Llama-3_Finetuning_on_custom_dataset_with_unsloth.ipynb)

14. RAG using  Llama3, Ollama and ChromaDB : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides/blob/main/GENAI_NOTEBOOKS/ollama_llama_chroma_rag.ipynb)
    
15. Llama3 Usecases: [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides)

16. RAG using Ro-LLM, Langchain and ChromaDB : [ğŸ‘‰Implementation Guideâ–¶ï¸](https://github.com/GURPREETKAURJETHRA/RAG-using-Ro-LLM-Langchain-and-ChromaDB)
---

#### **If you like this LLM Project do drop â­ to this repo**
#### Follow me on [![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/gurpreetkaurjethra/) &nbsp; [![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/GURPREETKAURJETHRA/)

---
